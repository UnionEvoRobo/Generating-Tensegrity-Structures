
--

Natural embryogenic processes unfold in a world which is intrinsically
stochastic and noisy.  When genotype are given multiple opportuntities
to embryogenically produce a phenotype,  it would seem that a noisy
embryogenic environment would cause significant variation on the set of
phenotypes that result.  Yet, the world is full of genotypes and
embryogenic systems (genotype plus embryogeny) that reliably achieve
extremly complex designs with very little variation among their
resulting phenotypes. 

After a little more thought on this, it occurs to me that the reward
for genotypes with high reliability is intrinsic: if a genotype can
reliably produce fit offspring, then it will be represented in the
surviving population proportionally to its reliability.  

I'll phrase this again in terms of the work I've been doing.  
Each genotype is decoded/grown/built (via embryogeny in a noisy,
stochastic environment) into a phenotype N times, and each of those N
results joins a larger population P (composed of the results of other
genotypes each also built N times).  Fit individuals among this larger
population are selected for (i.e. non-dominated individuals kept),
resulting in population P'.

Let's say that among genotype A's results, 10 survive selection, and
among genotype B's results, 50 survive.  If members of the next
generation are generated by randomly selecting two members of P' and
breeding them, then members of the new genration with genotype B as a
"parent" will be (on average) five times higher than those with genotype
A as a parent, right?. (Note that if another genotype, C can produce, even just
once, a result capable of dominating all of A's and B's results, then neither A
nor B will make it into P', so reliablity of result isn't enough).  A
nice thing about this is that terms I had been throwing around, "best",
"average", "yield", are subsumed by this model, and calculated
intrinsically by the dynamics of the system, so they don't need to be
artificially and explicitly and used for selection, as I had been doing
before (yield is the number of your "best" results that make it into P'
- average is irrelevant, because your "average" result will always be
dominated by your best result). 


Nonetheless, several questions arise.

- Is this intrinsic reward for high reliability enough to result in
genotypes with high embryogenic reliability? 

-  Will high reliabilty come into play at all?

- what are the properties of an embryogeny that allow it to achieve
reliable and consistent results?  Are they specific to a particular
implimentation, or can we generalize?

- Is this insight of mine brilliant, or blatant? (richard?)

I'd love any feedback on the matter
(preferably soon).

**********************************

Posted by  Shivakumar Viswanathan  (shiva@cs.brandeis.edu) on October 02, 2002
at 14:01:15.

In Reply to: " thoughts on variation, embryogeny"
posted by  John Rieffel  on October 02, 2002 at 13:10:10.


John,

This is the algorithm that I presented in March/April at the group 
meeting. I have a MATLAB version of the code, which may require a little 
cleaning up, if you want to use it.

As for your questions, the effect of differential reliability using this 
algorithm is very marked. In addition to simply a fixed number of 
offspring, when the constructing system can "deliberately" effect the 
reliability by aborting the offspring that it "believes" would not be 
competitive, it results in a rapid generation of highly reliable AND, 
more importantly, functionally viable offspring that arent necessarily 
identical. 

Conceptually, the interesting aspects of such an algorithm are:

*  The "genome-as-blueprint" is done away with completely. All that 
   matters is that the participation of the genome in the physics of 
   construction results in "fit" outcomes. When these "fit" outcomes
   are structurally identical only then is the genome seemingly acting
   as if it were a blueprint. So the "genome-as-blueprint" is really 
   just a special case of a general one where the genome results in
   functional offspring reliably. And the other extreme of this continuum 
   is what your algorithm does at present, where it accepts all outcomes
   independent of similarity or the lack of it.

*  Selection acts on individual phenotypes rather than on the NOMINAL or 
   REPRESENTATIVE individual computed using heuristic statistical 
   measures on populations of individuals from the same genome. 

*  The addition of the self-observing element, in this scheme, results in
   a pruning of the tree of possible outcomes. And the earlier the 
   distinctions can be made on this tree, the faster an individual can be 
   aborted. So this does not even require that N complete offspring be 
   generated each time, and the "N" is a variable with an upper bound 
   set by constructional resources available. 

There are all sorts of interesting formal properties that such a setup 
provides, with direct import on "body-brain" evolution and the claim of
full automation.


Shivakumar


****************************************************

Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 02, 2002 at
14:23:02.

In Reply to: " thoughts on variation, embryogeny"
posted by  John Rieffel  on October 02, 2002 at 13:10:10.

On Wed, 2 Oct 2002, DEMO Lab's WWWBoard MSG 1762 wrote:

> Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 02, 2002 at
> 13:10:10.
> 

> After a little more thought on this, it occurs to me that the reward
> for genotypes with high reliability is intrinsic: if a genotype can
> reliably produce fit offspring, then it will be represented in the
> surviving population proportionally to its reliability.  
> 

Yes, thats fine. BTW, in biological terms, the phenomenon of adaptation
that reduces the variance in phenotype (by presumably increasing fitness
mean) is called canalization (Waddington). (Note also that there are also
biological arguments favouring increased phenotypic variation in for
example varying environments. This is one of the arguments for the
advantage of recombination).

> Nonetheless, several questions arise.
> 
> - Is this intrinsic reward for high reliability enough to result in
> genotypes with high embryogenic reliability? 

So, if you have a story about why reliability is intrinsically valuable,
it is then fine to carry on explicitly rewarding reliability, no?

> - Is this insight of mine brilliant, or blatant? (richard?)

No its progress - we did know it already - but its fine to remind us that
the implicit selection for reliability of phenotype is 'natural'. That was
probably a bit burried yesterday.


> - what are the properties of an embryogeny that allow it to achieve
> reliable and consistent results?  Are they specific to a particular
> implimentation, or can we generalize?
> 

This is the as yet un-resolved crux, as I see it. What are you telling us
about canalization? e.g. canalization is possible (obvious?)/ its
important (obvious?)/ evolution can do it (pretty obvious, but its always
nice to have a simple simulation based model - (natural evolution, or
artificial evolution?, BTW))/ this particular evolutionary set-up can do
it (it can, but why would I care about a specific case?)

related questions: Is your intent to provide a model of a biological
process (like canalisation) and learn something about biology from it? Is
your intent to provide an engineering method (that happens to be inspired
by biological canalization)? Is your intent to tell us something general
about complex systems - e.g. the reliable generation of self-reproducing
complex systems in noisy environments? Or something else. 

(BTW. Its really nice work. Very clear method and results. I'm giving you
hassle about it only because you've produced something concrete enough and
clear enough that its easy to identify the next step to critique. We all
have difficulty getting through 'whats it good for?' sieve - just in case
you were feeling insecure ;) Well, I know I did ;)

love,
Richard.

************************************

Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 02, 2002 at
14:41:33.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Shivakumar Viswanathan  on October 02, 2002 at 14:01:15.

On Wed, 2 Oct 2002, DEMO Lab's WWWBoard MSG 1764 wrote:

> 
> In Reply to: " thoughts on variation, embryogeny"
> posted by  John Rieffel  on October 02, 2002 at 13:10:10.
> 

Remember that 'abortion' is the crudest way of being 'sensitive' to
developmental stochastisity, BTW.

Anyhoo, so John is demonstrating what can be done without any build-time
sensitivity (only evol-time sensitivity) to build stochasticity. 
It seems to me that this is a more useful distinction than the blueprint/
no-blueprint distinction. John would, I imagine, be quite happy to use a
fitness function that measured function rather than closeness to a
blueprint. But, the possibility of build-time sensitivity is a deeper
issue.

love,
Richard.

*********************************


Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 02, 2002 at
15:00:22.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Richard Watson  on October 02, 2002 at 14:41:33.

> Anyhoo, so John is demonstrating what can be done without any build-time
> sensitivity (only evol-time sensitivity) to build stochasticity. 
> It seems to me that this is a more useful distinction than the blueprint/
> no-blueprint distinction. John would, I imagine, be quite happy to use a
> fitness function that measured function rather than closeness to a
> blueprint. But, the possibility of build-time sensitivity is a deeper
> issue.

What do you mean by "build-time sensitivity?"

Anthony

******************************************


Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 02, 2002 at
15:20:47.

In Reply to: " thoughts on variation, embryogeny"
posted by  John Rieffel  on October 02, 2002 at 13:10:10.

> - Is this intrinsic reward for high reliability enough to result in
> genotypes with high embryogenic reliability? 

Are you asking this as an empircal or theoretical question?  In the first
case: try it.  In the second: I don't know.  :-)  Crudely, this is a
"flow" problem.  If the reliable guys hang around long enough that their
reliability can be detected (i.e., if there isn't some other mechanism
getting rid of them or increasing them first), then yes, reliability will
matter.
 
> - what are the properties of an embryogeny that allow it to achieve
> reliable and consistent results?  Are they specific to a particular
> implimentation, or can we generalize?

It's an inherently precise stochastic process.	Just ask Waddington.  
_Towards a Theoretical Bioloogy_ is the thing I was thinking of.  Three 
symposia.  A young Stuart Kauffmann attended one of them.

In other words, it's like the central limit theorem.  Lots of random 
stuff, when averaged, turns into a Gaussian.
 
> - Is this insight of mine brilliant, or blatant? (richard?)

Which insight would that be?  That reliable plans are 
overrepresented in the population?

Let me walk through what I thought you said, and correct me if I make a
mistake.  You're saying you have some plans, say A and B.  B is more
reliable than A.  You have them each make some instances, say 100.  You
put all these instances into a bag, and select on them according to how
well they match your ideal instance.  B was more reliable, so more of the
instances of B make it through selection.

Note that the instances have to have the plan attached to them tied to
them in this kind of scheme.  Otherwise you lose some information.

Given all that, this doesn't sound a whole lot different from an ordinary
evolutionary algorithm.  An individual is an instance + an assembly plan.  
To make a variant, you vary the plan using your operators.  You also make
a new instance.  So if B=(x,p), then B's offspring B' might be (x',p'),
where p' is a variant of the plan p, and x' is an instance generated from
p'.  OK, right, now you select one of these by comparing the x (x'...)
against your ideal.

This isn't exactly the same, but you get the idea.  Sometimes, p'=p, and
so the child is simply a new instance of p.  If the plan p is reliable,
these instances will tend to be the same, and if they're good, so is the
individual.  This is the flow rate business I was saying above:  how often
p'=p will determine how often you sample instances from plan.

Anyway, that's not the point though, is it?  Richard keeps asking this.  
You're not trying to show the world your brilliant new evolutionary
algorithm.  Frankly, I think you ought to use an off-the-shelf EMOO
algorithm, an off-the-shelf statistical representation of your individuals
(like mean, std dev, skew), and run things like that, to background that
stuff as much as possible.  Then you can emphasize your claims about 
assembly plans in noisy environments, whatever those claims might be.  :)

Anthony

*************************************************

Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 02, 2002 at
18:18:27.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Anthony Bucci  on October 02, 2002 at 15:00:22.

On Wed, 2 Oct 2002, DEMO Lab's WWWBoard MSG 1767 wrote:

> Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 02, 2002 at
> 15:00:22.
> 
> In Reply to: " Re: thoughts on variation, embryogeny"
> posted by  Richard Watson  on October 02, 2002 at 14:41:33.
> 
> > Anyhoo, so John is demonstrating what can be done without any build-time
> > sensitivity (only evol-time sensitivity) to build stochasticity. 
> > It seems to me that this is a more useful distinction than the blueprint/
> > no-blueprint distinction. John would, I imagine, be quite happy to use a
> > fitness function that measured function rather than closeness to a
> > blueprint. But, the possibility of build-time sensitivity is a deeper
> > issue.
> 
> What do you mean by "build-time sensitivity?"

That the instructions you give to the builder are sensitive to the results
of previous build actions (in the same lifetime) - the crudest kind of
build-time sensitivity being "if that didnt do what I wanted to do then
abort", but other simple kinds might be "if that didnt do what Iwanted to
do then try it again", etc.
Whereas, evo-time sensitivity is the demonstrated in the adaptation of
assembly plans that are balistic (in the liftime - i.e. a single build
execution of the plan) but are sensitive to stochasticity over
evolutionary time (as evidenced by the ability of evolution to find robust
plans).

love,
R.

*********************************************

Posted by  Shivakumar Viswanathan  (shiva@cs.brandeis.edu) on October 02, 2002
at 18:21:31.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Richard Watson  on October 02, 2002 at 14:41:33.



I'm not quite sure what you mean by 'crude':

'Abortion' is one, of many possible, consequences of being sensitive to 
developmental stochasticity. For example, the sensitivity could result in 
a call to another 'subroutine' or change in some 'variable'. But the 
sensitivity or ability to distinguish between the different outcomes of 
development (the need for which arises due to stochasticity) can be 
arbitrarily low or high, depending on the context. 

The 'crudeness' is in deliberately not performing a full blown functional 
testing of each phenotype individual in the actual world itself (i.e. by 
actually running it) but by restricting the sensitivity to the structure 
features during construction in the real world. Is this what you mean by 
being 'crude'?


--------------

As for being more or less useful than a blueprint/no-blueprint 
distinction:

I was pointing out that John's scheme could be seen as one extreme (i.e. 
of complete "build-time" insensitivity) of a broader space of varying 
build-time sensitivity. Also present in this space is the "blueprint" 
case, namely the procedures that are uniquely sensitive and selective of 
one specific structure X, i.e. as if the procedure were derived from a 
blueprint for X. So, what I'm saying is that John's scheme is the other 
extreme of the 'blueprint' case and this has nothing to do with his using 
a target structure as the fitness function. 

Conceiving of it in terms of 'Accept/abort' due to build-time sensitivity 
subsumes the blueprint/no-blueprint distinction, neither throwing away 
the benefits of blueprints (in tuning out stochasticity) but also 
allowing alternatives that are unaffected by the downstream algorithmic 
difficulties associated with evolving blueprints directly (typically when 
one desires fully or atleast quasi-autonomous body-brain evolution)

----------------


**************************************


Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
11:05:35.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Shivakumar Viswanathan  on October 02, 2002 at 18:21:31.


To back up a bit, how's this for an "Applying a Biologically-Inspired
Evolutionary Method to an Engineering" statement:

>From the evolution-as-engineering-design point of view, approaches using
embryogenic models (i.e. genome-as-assembly-plan) have been successful
in achieving complex design (cf. Hornby, Bongard et al), but are blind
to the prospect of noisy assembly, and hence brittle in its presence. 

If noise during assembly imposes a distribution of structres from a
single assembly plan, the goal is to develop assembly plans that are
robust to this noise.  Robusticity in an assembly plan is the property
of being able to consistently produce satisfactory results over the
course of multiple nondeterministic assemblies (and is, as a result, a
_relative_ measurement).  Robustness does _not_ require that all
of an assembly plan's satisfactory results be similar (in some
external subjective sense, i.e. similar in structure), merely that they
are comparably fit.

Adding a simple extension to evolutionary approch of earlier efforts
(the "algorithm" I described in the earlier post, in which each assembly
plan is built into 100 results, and these results are then selected for
over the standard objectives), I'd like to show, can result in assembly
plans that are rubost in the face of noisy assembly without any explicit
or external judgement (i.e. the "yield" metric I had been using before)
of rubusticity.

(So, for now at least, I'm not interested in evolving assembly procedures that
consistently produce identical results (i.e. canalization?), merely in
evolving assembly procedures that are consistent in producing successful
results.  This is a much smaller goal than Shiva's idea of adding to
embryogenesis the ability to test-and-abort.  In the long run, I think
that such a feature will be necessary to evolve highly complex systems,
and hope to work with Shiva in developing it). 


--------------------------------------------------------


Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 03, 2002 at
11:22:06.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  John Rieffel  on October 03, 2002 at 11:05:35.

On Thu, 3 Oct 2002, DEMO Lab's WWWBoard MSG 1774 wrote:

> Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
> 11:05:35.
> 
> In Reply to: " Re: thoughts on variation, embryogeny"
> posted by  Shivakumar Viswanathan  on October 02, 2002 at 18:21:31.
> 
> 
> To back up a bit, how's this for an "Applying a Biologically-Inspired
> Evolutionary Method to an Engineering" statement:
> 
> >From the evolution-as-engineering-design point of view, approaches using
> embryogenic models (i.e. genome-as-assembly-plan) have been successful
> in achieving complex design (cf. Hornby, Bongard et al), but are blind
> to the prospect of noisy assembly, and hence brittle in its presence. 

Well, they might be a bit - but they're not totally unable to accomodate
noisy environments - they can adapt to it over evolutionary time (i.e.
there is always an indirect selection pressure to have fit descendants
(i.e. given two indivs of equal fitness a robust one will have more fit 
descendants than a non-robust one so robust ones prosper better).
 > 

> If noise during assembly imposes a distribution of structres from a
> single assembly plan, the goal is to develop assembly plans that are
> robust to this noise.  Robusticity in an assembly plan is the property

whats wrong with "robustness" 

> of being able to consistently produce satisfactory results over the
> course of multiple nondeterministic assemblies (and is, as a result, a
> _relative_ measurement).  Robustness does _not_ require that all
> of an assembly plan's satisfactory results be similar (in some
> external subjective sense, i.e. similar in structure), merely that they
> are comparably fit.
> 

fine 

> Adding a simple extension to evolutionary approch of earlier efforts
> (the "algorithm" I described in the earlier post, in which each assembly
> plan is built into 100 results, and these results are then selected for
> over the standard objectives), I'd like to show, can result in assembly
> plans that are rubost in the face of noisy assembly without any explicit
> or external judgement (i.e. the "yield" metric I had been using before)
> of rubusticity.

You want to show plans getting more robust without using a high-yield
objective? i.e. you wont count the number of maximally fit phenotypes, but
you'll still reward for average fitness of phenotypes? Theres no
fundamental difference is there?

> 
> (So, for now at least, I'm not interested in evolving assembly procedures
that
> consistently produce identical results (i.e. canalization?), merely in

Yes, Im not sure if canalization is defined as consistent phenotypes or
consistent fitness - I know someone I can ask...

> evolving assembly procedures that are consistent in producing successful
> results.  This is a much smaller goal than Shiva's idea of adding to
> embryogenesis the ability to test-and-abort.	In the long run, I think
> that such a feature will be necessary to evolve highly complex systems,
> and hope to work with Shiva in developing it). 

So, your trying to develop a methodology for designing robust complex
systems?

love,
Richard.


--------------------------------------------------------


Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
11:37:42.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Richard Watson  on October 03, 2002 at 11:22:06.

> Well, they might be a bit - but they're not totally unable to accomodate
> noisy environments - they can adapt to it over evolutionary time (i.e.
> there is always an indirect selection pressure to have fit descendants
> (i.e. given two indivs of equal fitness a robust one will have more fit 
> descendants than a non-robust one so robust ones prosper better).

In my model yes.  Evolutionary time adaptation.  Earlier methods have a
1-to-1 mapping from individual genotype to phenotype (because there's no
noisy assembly), so either your single result is fit, in which case you
have descendants, or it isn't, in which case you don't.  

> fine 

> You want to show plans getting more robust without using a high-yield
> objective? i.e. you wont count the number of maximally fit phenotypes, but
> you'll still reward for average fitness of phenotypes? Theres no
> fundamental difference is there?

I don't reward for the average fitness of phenotypes.  There is no such
mapping from phenotypic fitness to genotypic fitness, except in the
evolutionary scale.

genotype A produces 50 results that survive selection
genotype B produces 10 results that survive selection

where selection, in this case, is non-domination over the objectives of
, for instance, (1) length, (2)bricks missing for goal, (3) extra
bricks.  Note absence of yield, or average, which are (artificial, in a
sense) properties of a genotype, and hence not measurable by analysis at
the phenotypic level.  Rather A is "instrinsically" rewarded by having
proportionally more surviving phenotypes than B, and hence more likely
to have more descendants.

> Yes, Im not sure if canalization is defined as consistent phenotypes or
> consistent fitness - I know someone I can ask...

Yes, but I'm suggesting that consistent fitness does not necessarily imply
consistent phenotype.

> So, your trying to develop a methodology for designing robust complex
> systems?

robust to noisy assembly, not robust in any other sense.

:)

jr



--------------------------------------------------------

Posted by  Gregory Hornby  (hornby@cs.brandeis.edu) on October 03, 2002 at
12:38:16.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  John Rieffel  on October 03, 2002 at 11:37:42.



On Thu, 3 Oct 2002, DEMO Lab's WWWBoard MSG 1776 wrote:

> Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
> 11:37:42.
> 
> In Reply to: " Re: thoughts on variation, embryogeny"
> posted by  Richard Watson  on October 03, 2002 at 11:22:06.
> 
> > Well, they might be a bit - but they're not totally unable to accomodate
> > noisy environments - they can adapt to it over evolutionary time (i.e.
> > there is always an indirect selection pressure to have fit descendants
> > (i.e. given two indivs of equal fitness a robust one will have more fit 
> > descendants than a non-robust one so robust ones prosper better).
> 
> In my model yes.  Evolutionary time adaptation.  Earlier methods have a
> 1-to-1 mapping from individual genotype to phenotype (because there's no
> noisy assembly), so either your single result is fit, in which case you
> have descendants, or it isn't, in which case you don't.  
> 

In fact, I do have noisy assembly of my genobots.  I construct and 
evaluate each genotype three times with different noise on the joint 
angles, with the individual's fitness being the lowest of these three 
results.  Also I believe Hod did something similar with GOLEM.
In Bongard's system, I think the creatures are growing/developing at the 
same time as they are being simulated.	In which case his system should be
reactive to noisy assembly -- although he doesn't evaluate in such an 
environment.

Greg


--------------------------------------------------------


Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 03, 2002 at
12:45:58.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  John Rieffel  on October 03, 2002 at 11:37:42.

> where selection, in this case, is non-domination over the objectives of
> , for instance, (1) length, (2)bricks missing for goal, (3) extra
> bricks.  Note absence of yield, or average, which are (artificial, in a
> sense) properties of a genotype, and hence not measurable by analysis at
> the phenotypic level.  Rather A is "instrinsically" rewarded by having
> proportionally more surviving phenotypes than B, and hence more likely
> to have more descendants.

I say that A is being *explicitly* rewarded.  What you described sounds 
like an ordinary EA.  

You may think it's not because you have a layer of indirection between
plans and instances (where the fitness is run), but that's a matter of
presentation, not a "real" difference.
 
> Yes, but I'm suggesting that consistent fitness does not necessarily imply
> consistent phenotype.

Be wary here.  Trying to say what "consistent phenotype" means is thorny.  
Because, you're making an arbitrary definition of what "the same"  
phenotype is, and saying that your plans do not necessarily produce "the
same" phenotype.  Someone else will come along and say "no, MY definition
of 'the same' is more appropriate than yours," and you'll argue till the
end of time over some irrelevant detail like that.

It doesn't really matter.  What matters is that stuff gets better.  You 
don't need a concept of "consistent phenotype" to say that.
 
> robust to noisy assembly, not robust in any other sense.

Meaning, plans tend to produce high-fitness instances.

What happens if you turn up the noise in your simulator?  E.g., what if
you make every operation fail (any time a block might fall over, it will).  
I think Richard suggested this.  Do your evolved plans still do well?  It
seems they might, so this is another layer of robustness you can talk
about.	Even if the builder has particularly bad luck that day, it *still*
has a decent chance of producing a good output.

AB



--------------------------------------------------------


Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
13:20:47.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Anthony Bucci  on October 03, 2002 at 12:45:58.


oy vey.

> I say that A is being *explicitly* rewarded.	What you described sounds 
> like an ordinary EA.	

Okay.  Yield is explicitly rewarded, but indirectly, and not through
direct calculation.  Better, I think, to have the "calculation"
intrinsic in the dynamics of the system, no?

> Be wary here.  Trying to say what "consistent phenotype" means is thorny.  

okay.

> It doesn't really matter.  What matters is that stuff gets better.  You 
> don't need a concept of "consistent phenotype" to say that.

yup.

> Meaning, plans tend to produce high-fitness instances.
> 
> What happens if you turn up the noise in your simulator?  E.g., what if

a quick test by hand - my best assembly plan, which got 75% on the 50%
noise used on the model  gets 43% yield when the noise is "turned up" to
90% chance of bricks (both vertical and cantilevered)  falling over, and
86% yield when noise is turned down to 10 %.  Here's the kicker: turned
up to 100% noise, it still gets 33% yield. I'm not sure what this says,
though.  I'm certainly not arguing that the solution isn't sensitive to
the noise model.

jr



--------------------------------------------------------


Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
13:48:24.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Gregory Hornby  on October 03, 2002 at 12:38:16.


> In fact, I do have noisy assembly of my genobots.  I construct and 
> evaluate each genotype three times with different noise on the joint 
> angles, with the individual's fitness being the lowest of these three 
> results. 

If I recall correctly, the noise in joint angles was relatively small -
do you know if it tended to have a large impact upon the fitness of the
resulting individual?  

So in your work the fitness of the poorest performing result is
attributed (directly) to the genotype.	So if you were to build an
individual 100 times, and 99 of the times it did very well, and the
100th it did poorly, the genotype would be judged poorly.  This seems
harsh, no?  In the system I want to use, the opposite would occur -
you're keeping the best (which may or may not be fit in the same manner 
(i.e. morphologicaly identical), only comparably fit).

> In Bongard's system, I think the creatures are growing/developing at the 
> same time as they are being simulated.

In "Evolving Complete Agents Using Artificial Ontogeny" (referenced in
one of your papers - thanks!), while the creatures do seem to be built
within the environment, it looks like the noise is only added once the
ontogeny is complete.	The fitnesses achieved over nine (noisy) runs
are averaged and attributed to the genotype as a fitness measure.  "By
averaging the agent's fitness values, we avoid evolving agents that only
perform well in a particular noisy environment".  But, I might add, as a
result they punish agents that with better maximums but worse averages.
If, for instance,  agent A and agent B are each evaluated ten times, and
A achieves a "fitness" of 10 five times and a fitness of zero five
times, ,and B achieves a fitness of 6 all ten times, then B will be
selected for over A.  Seems unfair, no?

Again, however, this is noisy evaluation, not noisy building.  What they
are trying to do with robustness to noisy evaluation, I am trying to do
with robustness to noisy construction. 

jr


--------------------------------------------------------


Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 03, 2002 at
15:03:18.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  John Rieffel  on October 03, 2002 at 13:48:24.

> > In fact, I do have noisy assembly of my genobots.  I construct and 
> > evaluate each genotype three times with different noise on the joint 
> > angles, with the individual's fitness being the lowest of these three 
> > results. 

That's not noisy assembly!  That's just wiggling the joints to ease the
pain of the transfer problem.
 
> But, I might add, as a
> result they punish agents that with better maximums but worse averages.

Ugh, that's more or less equivalent to punishing something with a good
mean but high variance, which is a clearer thing to do from a statistical
perspective.

I think one should MOO on mean and variance, maximizing the mean while
minimizing the variance.  Something like is more to the point, at least in 
some problems.

> If, for instance,  agent A and agent B are each evaluated ten times, and
> A achieves a "fitness" of 10 five times and a fitness of zero five
> times, ,and B achieves a fitness of 6 all ten times, then B will be
> selected for over A.	Seems unfair, no?

Let's see.  

    mean   var
A      5    25
B      6     0

Yeah, that's fair.  A's bad.  :-)

It's less clear if, say, A gets fitness of 4 all ten times.  Then, A and B 
are non-dominated.

Measures like this are bad because they are sensitive to the (often
arbitrary) scaling of the fitness function.  You could rescale this
fitness function and change the relationship, since variance (like max) is
higher order.  That's why you should use partial orders like I do.  ;-)

AB


--------------------------------------------------------


Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 03, 2002 at
15:05:44.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  John Rieffel  on October 03, 2002 at 13:48:24.

On Thu, 3 Oct 2002, DEMO Lab's WWWBoard MSG 1781 wrote:

> Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
> 13:48:24.
> 
> In Reply to: " Re: thoughts on variation, embryogeny"
> posted by  Gregory Hornby  on October 03, 2002 at 12:38:16.
> 
> If, for instance,  agent A and agent B are each evaluated ten times, and
> A achieves a "fitness" of 10 five times and a fitness of zero five
> times, ,and B achieves a fitness of 6 all ten times, then B will be
> selected for over A.	Seems unfair, no?

Anything that throws away information is unfair to something - whether it
be average, min or max. If you're after high robustness not fluke high
fitnesses then something biased towards the min end of the
distribution (rather than average or max) seems like the right bias to
have.

> 
> Again, however, this is noisy evaluation, not noisy building.  What they
> are trying to do with robustness to noisy evaluation, I am trying to do
> with robustness to noisy construction. 

Is there really any interesting difference? (Which is not to say that you
couldn't get a paper from it.) 

l,
R.


--------------------------------------------------------


Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 03, 2002 at
15:19:14.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Richard Watson  on October 03, 2002 at 15:05:44.

> > Again, however, this is noisy evaluation, not noisy building.  What they
> > are trying to do with robustness to noisy evaluation, I am trying to do
> > with robustness to noisy construction. 
> 
> Is there really any interesting difference? (Which is not to say that you
> couldn't get a paper from it.) 

In noisy building, a little bit of noise early in the construction process
can lead to a radically different shape in the end.  The noisy building
adds (or I should say enhances) the possibility of getting many distinct,
good shapes from one plan.  Call them eigenshapes or something.  Noisy
evaluation doesn't really do this, it just wiggles around the same basic
shape.

I think the verdict is still out as to whether that distinction is useful
or important.  However, it's an interesting thing to test.

That said, I don't think John's work really demonstrates anything along 
these lines yet, because he's using a fixed, target shape.  If he were to 
use a functional measure, like "will this hold 5 kilos," then things would 
become more interesting.

AB


--------------------------------------------------------


Posted by  Gregory Hornby  (hornby@cs.brandeis.edu) on October 03, 2002 at
16:45:52.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Anthony Bucci  on October 03, 2002 at 15:03:18.



On Thu, 3 Oct 2002, DEMO Lab's WWWBoard MSG 1783 wrote:

> Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 03, 2002 at
> 15:03:18.
> 
> In Reply to: " Re: thoughts on variation, embryogeny"
> posted by  John Rieffel  on October 03, 2002 at 13:48:24.
> 
> > > In fact, I do have noisy assembly of my genobots.  I construct and 
> > > evaluate each genotype three times with different noise on the joint 
> > > angles, with the individual's fitness being the lowest of these three 
> > > results. 
> 
> That's not noisy assembly!  That's just wiggling the joints to ease the
> pain of the transfer problem.

How is this not noisy assembly?  Isn't a large part of the transfer 
problem that of noisy assembly?  I'm not claiming that multiple evauations 
with different noise solves the problem noisy construction but this 
feature was added specifically to address noisy assembly and was 
sufficient for genobots and GOLEM.  
John may disagree, citing the roller which failed to work.  In this case 
the roller was not built within noise tolerance, and I do not believe it 
has ben shown that we can't build it within tolerance.	If we can't, then 
I just increase the noise in evaluation to match that which can be 
achieved.


> So in your work the fitness of the poorest performing result is
> attributed (directly) to the genotype.  So if you were to build an
> individual 100 times, and 99 of the times it did very well, and the
> 100th it did poorly, the genotype would be judged poorly.  This seems
> harsh, no? 

Again, I'm not claiming its a solution to noisy construction in general,
but it was sufficient for both Hod and myself.	I'm not sure about the 
details of Bongard's work, but if he were to use a noisy construction 
process (asssuming he is not already) it would seem that his developmental 
representation could handle some noise.  Similarly, the work with 
context-sensitive L-systems has potential to address noise in 
construction, and there has been work in which the growth of a plant is 
influenced by the environment (try Dr P's group at UCalgary).  Finally, 
John Gero (U Sydney?) has been interested in designs that develop under 
the influence of the environment.
My point here is not that people have looked at the problem and come 
up with a general solution, but that there does exist some work that 
addresses noisy construction (albei in a small way) and there are some 
systems which might be able to handle some degree of noise in the 
construction.

Greg


--------------------------------------------------------


Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 03, 2002 at
17:04:21.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Gregory Hornby  on October 03, 2002 at 16:45:52.


geez! where were you on tuesday?

;)



--------------------------------------------------------


Posted by  Anthony Bucci  (abucci@cs.brandeis.edu) on October 03, 2002 at
17:10:10.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Gregory Hornby  on October 03, 2002 at 16:45:52.

> How is this not noisy assembly?  Isn't a large part of the transfer 
> problem that of noisy assembly?

But...but you're adding noise to an existing thing, in order to evaluate 
it in a more robust way.  You have an existing structure, and you're 
twiddling it.  The very outcome of your assembly is not dependent on the 
noise.

That's not the same as having noise in your building process.  To do that,
you'd have to make your turtle's actions noisy.  Like, each time it tries
to put down a block, there's a chance that block might go somewhere else,
or not even go at all, or maybe two or three blocks will be put down
instead of one.   You'd get some funky looking tables if you did that.

AB

--------------------------------------------------------


Posted by  John Rieffel  (jrieffel@cs.brandeis.edu) on October 02, 2002 at
13:59:53.



As Keki pointed out, the "instrinsic reward" is in reliably producing
fit (non-dominated) phenotypes - the fit phenotypes resulting from the
same genotype don't  need to be identical in any sense other than in
being equally fit (non-dominated). 

But will they be?

Do they need to be?

All of this is independant of the Embryogenesis as Markov-Model, and
"reliability" being the ability to find a fixed point of the process -
that Jordan eet all were discussing.  I haven't thought much about that
yet.

jr


--------------------------------------------------------


Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 02, 2002 at
18:33:14.

In Reply to: " Re: thoughts on variation, embryogeny"
posted by  Shivakumar Viswanathan  on October 02, 2002 at 18:21:31.

On Wed, 2 Oct 2002, DEMO Lab's WWWBoard MSG 1770 wrote:

> Posted by  Shivakumar Viswanathan  (shiva@cs.brandeis.edu) on October 02,
2002
> at 18:21:31.
> 
> In Reply to: " Re: thoughts on variation, embryogeny"
> posted by  Richard Watson  on October 02, 2002 at 14:41:33.
> 
> 

I just mean, that if your a build-executor and you are sensitive to
how the build command you just executed came out in this actual build,
then the least sophisticated thing you can do in response to the actual
outcome is to abort the build if its not what you expected. In contrast,
more sophisticated things might be to repair that step of the build and/or
to adjust the commands you execute in the remainder of the build to
accomodate the observed bias in executions. In general, I suppose we could
quantify this by the number of	wasted build steps - if a repair takes
less steps than an abortion then its less 'crude'. Hows that?
l,
R.



--------------------------------------------------------


Posted by  Shivakumar Viswanathan  (shiva@cs.brandeis.edu) on October 02, 2002
at 19:24:57.

In Reply to: " Re: crudeness"
posted by  Richard Watson  on October 02, 2002 at 18:33:14.


Right, 'abortion' is crude in that sense but is the alternative really 
'repair'?
 
As I mentioned, the effect of sensitivity could be to call a 'subroutine', 
which could be equivalent to 'repair' but the reason for not saying 
'repair' was that it implies that the builder has an expectation of what 
the "right" outcome of the step ought to be. If in John's case, rather 
than a target structure, if the fitness were some other general behavior, 
then each procedure is associated with a distribution of final structures 
which may be all different. Since it is procedures that are being 
directly evolved there is no reference structure to compare with in 
order to determine if the outcome of that particular step was "right" or 
not.

So even though the builder-executor is sensitive to a change, what it 
ought to do when a change is registered is not defined a priori but an 
evolvable part of the procedure itself. In this sense, if the dumb builder 
seemed to be performing actions as if it were 'repairing' the structure 
as part of the procedure, that would be very cool. 

In my opinion, this is the kind of stuff of great interest in the problem 
of evolvable construction, in some sense defining the terrain to reach a 
situation of 'as-if-there-was-a-blueprint'.


:Shivakumar


--------------------------------------------------------



Posted by  Richard Watson  (rwatson@oeb.harvard.edu) on October 03, 2002 at
12:01:01.



My local expert say that when people talk about canalization they are
almost always thinking about stabilizing selection on phenotype, but _of
course_ the mechanism is the result of reducing variance in fitness.

More interesting cases are those where a distribution of phenotypes is
required to maximise fitness.

love,
Richard.


--------------------------------------------------------

Posted by  Shivakumar Viswanathan  (shiva@cs.brandeis.edu) on October 03, 2002
at 14:14:36.

In Reply to: " canalization (fwd)"
posted by  Richard Watson  on October 03, 2002 at 12:01:01.


I'm not entirely what aspect John is getting at with canalization but
the larger issue at stake with the build-time sensitivity etc in 
development, that I've been trying to chase down, is actually loosely 
similar to the claim in the paper you had sent earlier (Waddington's 
canalization revisited [Siegal and Bergman]), that canalization may come 
along for free to good extent with stable developmental interactions 
rather than explicit stabilizing selection. 


--------------------------------------------------------

http://www.demo.cs.brandeis.edu/Private/DEMO_board/messages/1782.html#postfp

